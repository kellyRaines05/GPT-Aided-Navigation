# GPT-Aided-Navigation
This project aims to enhance navigation for the visually impaied and blind by providing information about their immediate surroundings, up to at least twenty feet ahead of them. Vision language models such as GPT-4o brings a unique solution in daily situations users face when trying to envision their surroundings, details missed below/above detection by a walking stick or similar solutions currently being used.

## Setup simulate_gpt-4o_nav
1. Ensure carla_0.9.15/ and AdditionalMaps_0.9.15/ are downloaded (Windows Pre-built)
2. Launch carla_0.9.15/CarlaUE4
3. Run carla_script.py

For Ubuntu systems, download the pre-build [here](https://github.com/carla-simulator/carla/releases/tag/0.9.15/)

